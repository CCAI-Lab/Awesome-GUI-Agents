# Awesome-GUI-Agents
A curated list for **GUI Agents**

**Table Content:** 

- [Updates](# updates) 
- [Contributing](#contri) 
- [Four Module of GUI Agents](#module)
- [Paper List](#paper-list) 
  - [GUI Agents List](#agentlist) 
  - [GUI Agents Datasets & Benchmark List](#datasets) 

![Alt text](Figures/overview.png)

## ðŸš€ [Updates](#updates) 

* March 24, 2025: We updated the repository and released our comprehensive survey on GUI Agents.

## ðŸ’® [Contributing](#contri)

If you'd like to include your paper, or need to update any details such as github repo information or code URLs, please feel free to submit a pull request. 

## [Four Module of GUI Agents](#module)

We have divided GUI Agents into four modules: perception, exploration, planning, and interaction, as shown below:

![Alt text](Figures/module.jpg)

## [Paper List](#paperlist)

We have dedicated a separate chapter to datasets and benchmarks for GUI Agents, with all content presented in chronological order.

### [GUI Agents List](#agentlist)
| Title & Time | Introduction | Links |
|:--|  :----: | :---:|
| Advancing Mobile GUI Agents: A Verifier-Driven  Approach to Practical Deployment (2025-3) | <img width="1002" alt="image" src="figures/verifiergui.png" > | [Github]() <br/> [Paper](https://www.arxiv.org/abs/2503.15937) |
| API Agents vs. GUI Agents: Divergence and Convergence (2025-3) | <img width="1002" alt="image" src="figures/apivsgui.png" > | [Github]() <br/> [Paper](https://arxiv.org/abs/2503.11069) |
| AppAgentX: Evolving GUI Agents as Proficient Smartphone Users (2025-3) | <img width="1002" alt="image" src="figures/appagentx.png" > | [Github](https://github.com/Westlake-AGI-Lab/AppAgentX) <br/> [Paper](https://arxiv.org/pdf/2503.02268) |
| Think Twice, Click Once: Enhancing GUI Grounding via Fast and Slow Systems (2025-3) | <img width="1002" alt="image" src="figures/focus.png" > | [Github](https://github.com/sugarandgugu/Focus) <br/> [Paper](https://arxiv.org/pdf/2503.06470) |
| UI-TARS: Pioneering Automated GUI Interaction with Native Agents  (2025-2) | <img width="1002" alt="image" src="figures/uitars.png" > | [Github](https://github.com/bytedance/UI-TARS) <br/> [Paper](https://arxiv.org/abs/2501.12326) |
| Mobile-Agent-E: Self-Evolving Mobile Assistant for Complex Tasks (2025-1) | <img width="1002" alt="image" src="figures/mobileagente.png" > | [Github](https://github.com/X-PLUG/MobileAgent/tree/main/Mobile-Agent-E) <br/> [Paper](https://arxiv.org/abs/2501.11733) |
| InfiGUIAgent: A Multimodal Generalist GUI Agent with Native Reasoning and Reflection (2025-1) | <img width="1002" alt="image" src="figures/infiagent.png" > | [Github](https://github.com/Reallm-Labs/InfiGUIAgent) <br/> [Paper](https://arxiv.org/abs/2501.04575) |
| OS-Genesis: Automating GUI Agent Trajectory Construction via  Reverse Task Synthesis (2024-12) | <img width="1002" alt="image" src="figures/osgenesis.png" > | [Github](https://github.com/OS-Copilot/OS-Genesis) <br/> [Paper](https://arxiv.org/abs/2412.19723) |
| PC Agent: While You Sleep, AI Works - A Cognitive Journey into Digital World (2024-12) | <img width="1002" alt="image" src="figures/pcagent.png" > | [Github](https://github.com/GAIR-NLP/PC-Agent) <br/> [Paper](https://arxiv.org/abs/2412.17589) |
| Aria-UI: Visual Grounding for GUI Instructions (2024-12) | <img width="1002" alt="image" src="figures/ariaui.png" > | [Github](https://github.com/AriaUI/Aria-UI) <br/> [Paper](https://arxiv.org/abs/2412.16256) |
| Iris: Breaking GUI Complexity with Adaptive Focus and Self-Refining (2024-12) | <img width="1002" alt="image" src="figures/iris.png" > | [Github]() <br/> [Paper](https://arxiv.org/abs/2412.10342) |
| AgentTrek : AGENT TRAJECTORY SYNTHESIS  VIA GUIDING REPLAY WITH WEB TUTORIALS (2024-12) | <img width="1002" alt="image" src="figures/agenttrek.png" > | [Github](https://github.com/xlang-ai/AgentTrek) <br/> [Paper](https://arxiv.org/abs/2412.09605) |
| AGUVIS: UNIFIED PURE VISION AGENTS FOR  AUTONOMOUS GUI INTERACTION (2024-12) | <img width="1002" alt="image" src="figures/aguvis.png"> | [Github](https://github.com/xlang-ai/aguvis) <br/> [Paper](https://arxiv.org/abs/2412.04454) |
| Ponder & Press: Advancing Visual GUI Agent  towards General Computer Control (2024-12) |   <img width="1002" alt="image" src="figures/ponder.png">    |  [Github]() <br/> [Paper](https://arxiv.org/abs/2412.01268)  |
| ShowUI: One Vision-Language-Action Model for GUI Visual Agent (2024-11) |   <img width="1002" alt="image" src="figures/showui.png">    | [Github](https://github.com/showlab/ShowUI) <br/> [Paper](https://arxiv.org/abs/2411.17465) |
| The Dawn of GUI Agent: A Preliminary  Case Study with Claude 3.5 Computer Use (2024-11) |  <img width="1002" alt="image" src="figures/claude3.5.png">  |  [Github]() <br/> [Paper](https://arxiv.org/abs/2411.10323)  |
| OS-ATLAS: A FOUNDATION ACTION MODEL FOR  GENERALIST GUI AGENTS (2024-10) |   <img width="1002" alt="image" src="figures/osatlas.png">   | [Github](https://github.com/OS-Copilot/OS-Atlas) <br/> [Paper](https://arxiv.org/abs/2410.23218) |
| AutoGLM: Autonomous Foundation Agents for GUIs (2024-10)     |   <img width="1002" alt="image" src="figures/autoglm.png">   |  [Github]() <br/> [Paper](https://arxiv.org/abs/2411.00820)  |
| FERRET-UI 2: MASTERING UNIVERSAL USER INTERFACE UNDERSTANDING ACROSS PLATFORMS (2024-10) |  <img width="1002" alt="image" src="figures/ferretui2.png">  | [Github](https://github.com/apple/ml-ferret) <br/> [Paper](https://arxiv.org/abs/2410.18967) |
| AutoWebGLM: A Large Language Model-based Web Navigating Agent  (2024-10) | <img width="1002" alt="image" src="figures/autowebglm.png">  | [Github](https://github.com/THUDM/AutoWebGLM) <br/> [Paper](https://arxiv.org/abs/2404.03648) |
| AGENT S: AN OPEN AGENTIC FRAMEWORK THAT  USES COMPUTERS LIKE A HUMAN  (2024-10) |   <img width="1002" alt="image" src="figures/agentS.png">    | [Github](https://github.com/simular-ai/Agent-S) <br/> [Paper](https://arxiv.org/abs/2410.08164) |
| Navigating the Digital World as Humans Do:  UNIVERSAL VISUAL GROUNDING FOR GUI AGENTS (2024-10) |   <img width="1002" alt="image" src="figures/uground.png">   | [Github](https://github.com/OSU-NLP-Group/UGround) <br/> [Paper](https://arxiv.org/abs/2410.05243) |
| MOBILEFLOW: A MULTIMODAL LLM FOR MOBILE GUI AGENT (2024-8)   | <img width="1002" alt="image" src="figures/mobileflow.png">  |  [Github]() <br/> [Paper](https://arxiv.org/abs/2407.04346)  |
| AppAgent v2: Advanced Agent for Flexible Mobile Interactions (2024-8) | <img width="1002" alt="image" src="figures/appagentv2.png">  | [Github](https://github.com/TencentQQGYLab/AppAgent) <br/> [Paper](https://arxiv.org/abs/2408.11824) |
| OmniParser for Pure Vision Based GUI Agent (2024-8)          | <img width="1002" alt="image" src="figures/omniparser.png">  | [Github](https://github.com/microsoft/OmniParser) <br/> [Paper](https://arxiv.org/abs/2408.00203) |
| OmniACT: A Dataset and Benchmark for Enabling  Multimodal Generalist Autonomous Agents for Desktop (2024-7) |   <img width="1002" alt="image" src="figures/omniact.png">   |  [Github]() <br/> [Paper](https://arxiv.org/abs/2402.17553)  |
| Android in the Zoo: Chain-of-Action-Thought for GUI Agents (2024-7) |    <img width="1002" alt="image" src="figures/aitz.png">     | [Github](https://github.com/IMNearth/CoAT) <br/> [Paper](https://arxiv.org/abs/2403.02713) |
| CRADLE: Empowering Foundation Agents Towards General Computer Control (2024-7) |   <img width="1002" alt="image" src="figures/cradle.png">    | [Github](https://github.com/BAAI-Agents/Cradle) <br/> [Paper](https://arxiv.org/abs/2403.03186) |
| VGA: Vision GUI Assistant - Minimizing Hallucinations through Image-Centric Fine-Tuning (2024-6) |     <img width="1002" alt="image" src="figures/vga.png">     | [Github](https://github.com/Linziyang1999/Vision-GUI-assistant) <br/> [Paper](https://arxiv.org/abs/2406.14056) |
| WebVoyager: Building an End-to-End Web Agent with Large Multimodal Models (2024-6) | <img width="1002" alt="image" src="figures/webvoyager.png">  | [Github](https://github.com/MinorJerry/WebVoyager) <br/> [Paper](https://arxiv.org/abs/2401.13919) |
| Mobile-Agent-v2: Mobile Device Operation Assistant with Effective Navigation via Multi-Agent Collaboration (2024-6) | <img width="1002" alt="image" src="figures/mobileagent-v2.png"> | [Github](https://github.com/X-PLUG/MobileAgent/tree/main/Mobile-Agent-v2) <br/> [Paper](https://arxiv.org/abs/2406.01014) |
| SWE-agent: Agent-Computer Interfaces Enable Automated Software Engineering (2024-5) |  <img width="1002" alt="image" src="figures/sweagent.png">   | [Github](https://github.com/SWE-agent/SWE-agent) <br/> [Paper](https://arxiv.org/abs/2405.15793) |
| UFO : A UI-Focused Agent for Windows OS Interaction (2024-5) |     <img width="1002" alt="image" src="figures/ufo.png">     | [Github](https://github.com/microsoft/UFO) <br/> [Paper](https://arxiv.org/abs/2402.07939) |
| MOBILE-AGENT: AUTONOMOUS MULTI-MODAL MOBILE  DEVICE AGENT WITH VISUAL PERCEPTION (2024-4) | <img width="1002" alt="image" src="figures/mobile-agent.png"> | [Github](https://github.com/X-PLUG/MobileAgent/tree/main/Mobile-Agent) <br/> [Paper](https://arxiv.org/abs/2401.16158) |
| WebArena: A REALISTIC WEB ENVIRONMENT FOR  BUILDING AUTONOMOUS AGENTS (2024-4) |  <img width="1002" alt="image" src="figures/webarena.png">   | [Github](https://github.com/web-arena-x/webarena) <br/> [Paper](https://arxiv.org/abs/2307.13854) |
| TRAINING A VISION LANGUAGE MODEL AS  SMARTPHONE ASSISTANT (2024-4) |  <img width="1002" alt="image" src="figures/tdecison.png">   |  [Github]() <br/> [Paper](https://arxiv.org/abs/2404.08755)  |
| GPT-4V(ision) is a Generalist Web Agent, if Grounded (SeeAct)(2024-3) | <img width="1002" alt="image" src="figures/gpt4vgrounded.png"> | [Github](https://github.com/OSU-NLP-Group/SeeAct) <br/> [Paper](https://arxiv.org/abs/2401.01614) |
| AutoDroid: LLM-powered Task Automation in Android (2024-3)   |  <img width="1002" alt="image" src="figures/autodroid.png">  | [Github](https://github.com/MobileLLM/AutoDroid) <br/> [Paper](https://arxiv.org/abs/2308.15272) |
| SeeClick: Harnessing GUI Grounding for Advanced Visual GUI Agents (2024-2) |  <img width="1002" alt="image" src="figures/seeclick.png">   | [Github](https://github.com/njucckevin/SeeClick) <br/> [Paper](https://arxiv.org/abs/2401.10935) |
| OS-Copilot: Towards Generalist Computer Agents with Self-Improvement (2024-2) |  <img width="1002" alt="image" src="figures/oscopilot.png">  | [Github](https://github.com/OS-Copilot/OS-Copilot) <br/> [Paper](https://arxiv.org/abs/2402.07456) |
| Understanding the Weakness of Large Language Model Agents within a Complex Android Environment (2024-2) | <img width="1002" alt="image" src="figures/scalable_mobile.png"> |  [Github]() <br/> [Paper](https://arxiv.org/abs/2402.06596)  |
| MOBILEAGENT: ENHANCING MOBILE CONTROL VIA  HUMAN-MACHINE INTERACTION AND SOP INTEGRATION (2024-1) | <img width="1002" alt="image" src="figures/mobileagent.png"> |  [Github]() <br/> [Paper](https://arxiv.org/abs/2401.04124)  |
| ASSISTGUI: Task-Oriented Desktop Graphical User Interface Automation (2024-1) |  <img width="1002" alt="image" src="figures/assistgui.png">  | [Github](https://github.com/showlab/assistgui) <br/> [Paper](https://arxiv.org/abs/2312.13108) |
| AppAgent: Multimodal Agents as Smartphone Users ï¼ˆ2023-12ï¼‰  |  <img width="1002" alt="image" src="figures/appagent.png">   | [Github](https://github.com/TencentQQGYLab/AppAgent) <br/> [Paper](https://arxiv.org/abs/2312.13771) |
| CogAgent: A Visual Language Model for GUI Agents ï¼ˆ2023-12ï¼‰ | <img width="650" height="450" alt="image" src="figures/cogagent.png"> | [Github](https://github.com/THUDM/CogAgent) <br/> [Paper](https://arxiv.org/abs/2312.08914) |
| MIND2WEB: Towards a Generalist Agent for the Web ï¼ˆ2023-12ï¼‰ | <img width="1002" height="280" alt="image" src="figures/mind2web.png"> | [Github](https://github.com/OSU-NLP-Group/Mind2Web) <br/> [Paper](https://arxiv.org/abs/2306.06070) |
| Set-of-Mark Prompting Unleashes  Extraordinary Visual Grounding in GPT-4V ï¼ˆ2023-11ï¼‰ | <img width="1002" height="350" alt="image" src="figures/som.png"> | [Github](https://github.com/microsoft/SoM) <br/> [Paper](https://arxiv.org/abs/2310.11441) |
| META-GUI: Towards Multi-modal Conversational Agents on Mobile GUI (2022-12) |<img width="1002" alt="image" src="figures/metagui.png"> |[Github](https://github.com/X-LANCE/META-GUI-baseline) <br/> [Paper](https://arxiv.org/abs/2205.11029)|
|UIBert: Learning Generic Multimodal Representations for UI Understanding (2021-8) |<img width="1002" alt="image" src="figures/UIBert.png"> |[Github](https://github.com/google-research-datasets/uibert) <br> [Paper](https://arxiv.org/abs/2107.13731)|


### [GUI Agents  Datasets & Benchmark List](#datasets)
